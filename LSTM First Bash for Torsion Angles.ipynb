{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM first attempt\n",
    "\n",
    "## Overview\n",
    "\n",
    "This is my first attempt at creating a neural network that has some knowledge of the order of the data coming into it. \n",
    "\n",
    "I'm using a basic LSTM design. It consists of a recurrent neural network that is *unrolled* a number of times. In our case, it is unrolled max_cdr_length/31 times. Each cell has 128 neurons that are fully connected. \n",
    "\n",
    "This LSTM then spits out to the final fully connected layer that has weights and a bias. It essentially converts the 128 outputs, down to 124 for our 31 * 4 angles output.\n",
    "\n",
    "## Details\n",
    "\n",
    "Some things remain the same. We are still using the same bitfield representation as before (i.e a vector 21 items long with a single '1' where the amino acid should be). We still use the masks but we also introduce the length variable. This allows us to select which of the unrolled steps we are counting as the *last relevant block*. Also, the tensorflow rnn function takes a length parameter so we send in the length here.\n",
    "\n",
    "I've gone back to batching as this network takes longer to train. I've also introduced *dropout* as a regularisation step, simply because it seems to work apparently. Not sure why though? This means setting the dropout probability at training and validation time.\n",
    "\n",
    "For some reason, the validation batch has to be the same size as the training one. No idea why but it doesn't seem to matter too much. I choose randomly from the entire set each time.\n",
    "\n",
    "### Epochs\n",
    "\n",
    "It turns out we can present the same training data multiple times to the network. Now I'd previously thought this was a bad idea. Turns out, not so much. I can't find any actual data on this though so I think I need to check up on this. However, accuracy did seem to increas a little with more epochs.\n",
    "\n",
    "\n",
    "## Handy Links\n",
    "\n",
    "The following came in rather handy:\n",
    "\n",
    "* https://stackoverflow.com/questions/34670112/tensorflow-rnn-with-varying-length-sentences\n",
    "* https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537\n",
    "* https://jasdeep06.github.io/posts/Understanding-LSTM-in-Tensorflow-MNIST/\n",
    "* https://colah.github.io/posts/2014-07-NLP-RNNs-Representations/\n",
    "* https://stackoverflow.com/questions/34670112/tensorflow-rnn-with-varying-length-sentences\n",
    "* http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/\n",
    "* https://danijar.com/variable-sequence-lengths-in-tensorflow/ * this one is pretty good and covers the important points \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, math, random\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Import our shared util\n",
    "parentdir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "os.sys.path.insert(0,parentdir)\n",
    "from common.util import *\n",
    "\n",
    "FLAGS = NNGlobals()\n",
    "# A higher learning rate seems good as we have few examples in this data set.\n",
    "# Would that be correct do we think?\n",
    "FLAGS.learning_rate = 0.35\n",
    "FLAGS.pickle_filename = 'pdb_martin_03.pickle'\n",
    "FLAGS.lstm_size = 128   # number of neurons per LSTM cell do we think? \n",
    "FLAGS.num_epochs = 5    # number of loops around the training set\n",
    "\n",
    "# Import common items\n",
    "parentdir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "os.sys.path.insert(0,parentdir)\n",
    "from common import gen_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for the various elements of our graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name ):\n",
    "  ''' For now I use truncated normals with stdddev of 0.1.'''\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1, name=name)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "  initial = tf.constant(1.0, shape=shape, name=name)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def lstm_cell(size, kprob):\n",
    "  ''' Return an LSTM Cell or other RNN type cell. We\n",
    "  have a few choices. We can even throw in a bit of\n",
    "  dropout if we want.'''\n",
    "\n",
    "  cell= tf.nn.rnn_cell.BasicLSTMCell(size)\n",
    "  #cell = tf.nn.rnn_cell.GRUCell(size)\n",
    "  #cell = tf.nn.rnn_cell.BasicRNNCell(size)\n",
    "  cell = tf.nn.rnn_cell.DropoutWrapper(cell=cell, output_keep_prob=kprob)\n",
    "  return cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_relevant(output, length):\n",
    "  ''' Taken from https://danijar.com/variable-sequence-lengths-in-tensorflow/\n",
    "  Essentially, we want the last output after the total CDR has been computed.\n",
    "  That output is then converted to our 4 * max_cdr output. '''\n",
    "  batch_size = tf.shape(output)[0]\n",
    "  max_length = tf.shape(output)[1]\n",
    "  out_size = int(output.get_shape()[2])\n",
    "  index = tf.range(0, batch_size) * FLAGS.max_cdr_length + (length - 1)\n",
    "  flat = tf.reshape(output, [-1, out_size])\n",
    "  relevant = tf.gather(flat, index)\n",
    "  return relevant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph() :\n",
    "  graph = tf.Graph()\n",
    "\n",
    "  with tf.device('/gpu:0'):\n",
    "    with graph.as_default():\n",
    "      # Input data. We take in padded CDRs but feed in a length / mask as well\n",
    "      # Apparently the dynamic RNN thingy can cope with variable lengths\n",
    "      tf_train_dataset = tf.placeholder(tf.int32, [None, FLAGS.max_cdr_length, FLAGS.num_acids],name=\"train_input\") \n",
    "      output_size = FLAGS.max_cdr_length * 4\n",
    "      dmask = tf.placeholder(tf.float32, [None, output_size], name=\"dmask\")\n",
    "      x = tf.cast(tf_train_dataset, dtype=tf.float32)\n",
    "      \n",
    "      # Since we are using dropout, we need to have a placeholder, so we dont set \n",
    "      # dropout at validation time\n",
    "      keep_prob = tf.placeholder(tf.float32, name=\"keepprob\")\n",
    "\n",
    "\n",
    "      # This is the number of unrolls I think - sequential cells\n",
    "      # In this example, I'm going for max_cdr_length as we want all the history\n",
    "      # This will take a while and it is dynamically sized based on the inputs.\n",
    "      sizes = []\n",
    "      for i in range(0,FLAGS.max_cdr_length):\n",
    "        sizes.append(FLAGS.lstm_size)\n",
    "      rnn_layers = [lstm_cell(size, keep_prob) for size in sizes]\n",
    "      multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "      \n",
    "      # 'outputs' is a tensor of shape [batch_size, max_cdr_length, lstm_size]\n",
    "      # 'state' is a N-tuple where N is the number of LSTMCells containing a\n",
    "      # tf.contrib.rnn.LSTMStateTuple for each cell\n",
    "      length = create_length(x)\n",
    "      outputs, state = tf.nn.dynamic_rnn(cell=multi_rnn_cell, inputs=x, dtype=tf.float32, sequence_length = length)\n",
    "      relevant  = last_relevant(outputs, length)\n",
    "      test = tf.placeholder(tf.float32, [None, output_size], name=\"train_test\")\n",
    "\n",
    "      # Output layer converts our LSTM to 4 outputs (4 angles)\n",
    "      W_o = weight_variable([FLAGS.lstm_size, output_size], \"weight_output\")\n",
    "      b_o = bias_variable([output_size],\"bias_output\")\n",
    "\n",
    "      # I use tanh to bound the results between -1 and 1 \n",
    "      y_conv = tf.tanh( ( tf.matmul(relevant, W_o) + b_o) * dmask, name=\"output\")\n",
    "      variable_summaries(y_conv, \"y_conv\")\n",
    "\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mask(batch):\n",
    "  ''' create a mask for our fully connected layer, which\n",
    "  is a [1] shape that is max_cdr * 4 long.'''\n",
    "  mask = []\n",
    "  for model in batch:\n",
    "    mm = []\n",
    "    for cdr in model:\n",
    "      tt = 1\n",
    "      if not 1 in cdr:\n",
    "        tt = 0\n",
    "      for i in range(0,4):\n",
    "        mm.append(tt)\n",
    "    mask.append(mm)\n",
    "  return np.array(mask,dtype=np.float32)\n",
    "\n",
    "def create_length(batch):\n",
    "  ''' return the actual lengths of our CDR here. Taken from\n",
    "  https://danijar.com/variable-sequence-lengths-in-tensorflow/ '''\n",
    "  used = tf.sign(tf.reduce_max(tf.abs(batch), 2))\n",
    "  length = tf.reduce_sum(used, 1)\n",
    "  length = tf.cast(length, tf.int32)\n",
    "  return length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(goutput, gtest):\n",
    "  ''' Our error function which we will try to minimise'''\n",
    "  # We find the absolute difference between the output angles and the training angles\n",
    "  # Can't use cross entropy because thats all to do with probabilities and the like\n",
    "  # Basic error of sum squares diverges to NaN due to gradient so I go with reduce mean\n",
    "  # Values of -3.0 are the ones we ignore\n",
    "  # This could go wrong as adding 3.0 to -3.0 is not numerically stable\n",
    "  mask = tf.sign(tf.add(gtest,3.0))\n",
    "  basic_error = tf.square(gtest-goutput) * mask\n",
    "  \n",
    "  # reduce mean doesnt work here as we just want the numbers where mask is 1\n",
    "  # We work out the mean ourselves\n",
    "  basic_error = tf.reduce_sum(basic_error)\n",
    "  basic_error /= tf.reduce_sum(mask)\n",
    "  return basic_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_session(graph, datasets):\n",
    "  ''' Run the session once we have a graph, training methodology and a dataset '''\n",
    "  with tf.device('/gpu:0'):\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "      training_input, training_output, validate_input, validate_output, test_input, test_output = datasets\n",
    "      # Pull out the bits of the graph we need\n",
    "      ginput = graph.get_tensor_by_name(\"train_input:0\")\n",
    "      gtest = graph.get_tensor_by_name(\"train_test:0\")\n",
    "      goutput = graph.get_tensor_by_name(\"output:0\")\n",
    "      gmask = graph.get_tensor_by_name(\"dmask:0\")\n",
    "      gprob = graph.get_tensor_by_name(\"keepprob:0\")\n",
    "\n",
    "      # Working out the accuracy\n",
    "      basic_error = cost(goutput, gtest) \n",
    "      # Setup all the logging for tensorboard \n",
    "      variable_summaries(basic_error, \"Error\")\n",
    "      merged = tf.summary.merge_all() \n",
    "      train_writer = tf.summary.FileWriter('./summaries/train',graph)\n",
    "      \n",
    "      # So far, I have found Gradient Descent still wins out at the moment\n",
    "      # https://stackoverflow.com/questions/36162180/gradient-descent-vs-adagrad-vs-momentum-in-tensorflow\n",
    "      \n",
    "      #train_step = tf.train.GradientDescentOptimizer(FLAGS.learning_rate).minimize(basic_error)\n",
    "      train_step = tf.train.AdagradOptimizer(FLAGS.learning_rate).minimize(basic_error) \n",
    "      #train_step = tf.train.AdamOptimizer(1e-4).minimize(basic_error)\n",
    "      #train_step = tf.train.MomentumOptimizer(FLAGS.learning_rate, 0.1).minimize(basic_error)\n",
    "      \n",
    "      tf.global_variables_initializer().run()\n",
    "      print('Initialized')\t\n",
    "\n",
    "      for i in range(0,FLAGS.num_epochs):\n",
    "        stepnum = 0\n",
    "        FLAGS.next_batch = 0\n",
    "\n",
    "        while FLAGS.next_batch < len(training_input):\n",
    "          batch_is, batch_os = next_batch(training_input, training_output, FLAGS)\n",
    "          batch_iv, batch_ov = random_batch(validate_input, validate_output, FLAGS)\n",
    "          mask = create_mask(batch_is)\n",
    "          summary, _ = sess.run([merged, train_step],\n",
    "              feed_dict={ginput: batch_is, gtest: batch_os, gmask: mask, gprob: 0.5})\n",
    "          \n",
    "          # Find the accuracy at every step, but only print every 100\n",
    "          # We have to batch here too for some reason? LSTM or something?\n",
    "          mask = create_mask(batch_iv)\n",
    "          train_accuracy = basic_error.eval(\n",
    "              feed_dict={ginput: batch_iv, gtest: batch_ov,  gmask: mask, gprob: 1.0}) \n",
    "          \n",
    "          if stepnum % 10 == 0:\n",
    "            print('step %d, training accuracy %g' % (stepnum, train_accuracy))\n",
    "          \n",
    "          #dm = gmask.eval(feed_dict={ginput: item_is, gtest: item_os, gmask: mask}) \n",
    "          #print(dm)\n",
    "          train_writer.add_summary(summary, stepnum)\n",
    "          stepnum += 1\n",
    "\n",
    "      # save our trained net\n",
    "      saver = tf.train.Saver()\n",
    "      saver.save(sess, 'saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_saved(datasets):\n",
    "  ''' Load the saved version and then test it against the validation set '''\n",
    "  with tf.Session() as sess:\n",
    "    graph = sess.graph\n",
    "    saver = tf.train.import_meta_graph('saved.meta')\n",
    "    saver.restore(sess, 'saved')\n",
    "    training_input, training_output, validate_input, validate_output, test_input, test_output = datasets\n",
    "    goutput = graph.get_tensor_by_name(\"output:0\")\n",
    "    ginput = graph.get_tensor_by_name(\"train_input:0\")\n",
    "    gmask = graph.get_tensor_by_name(\"dmask:0\")\n",
    "    gprob = graph.get_tensor_by_name(\"keepprob:0\")\n",
    "    mask = create_mask(validate_input)\n",
    "    res = sess.run([goutput], feed_dict={ginput: validate_input, gmask: mask, gprob: 1.0})\n",
    "\n",
    "    # Now lets output a random example and see how close it is, as well as working out the \n",
    "    # the difference in mean values. Don't adjust the weights though\n",
    "    r = random.randint(0, len(validate_input)-1)\n",
    "\n",
    "    print(\"Actual              Predicted\")\n",
    "    for i in range(0,len(validate_input[r])):\n",
    "      sys.stdout.write(bitmask_to_acid(FLAGS, validate_input[r][i]))\n",
    "      phi = math.degrees(math.atan2(validate_output[r][i*4], validate_output[r][i*4+1]))\n",
    "      psi = math.degrees(math.atan2(validate_output[r][i*4+2], validate_output[r][i*4+3]))\n",
    "      sys.stdout.write(\": \" + \"{0:<8}\".format(\"{0:.3f}\".format(phi)) + \" \")\n",
    "      sys.stdout.write(\"{0:<8}\".format(\"{0:.3f}\".format(psi)) + \" \")\n",
    "      phi = math.degrees(math.atan2(res[0][r][i*4], res[0][r][i*4+1]))\n",
    "      psi = math.degrees(math.atan2(res[0][r][i*4+2], res[0][r][i*4+3]))\n",
    "      sys.stdout.write(\" | \" + \"{0:<8}\".format(\"{0:.3f}\".format(phi)) + \" \")\n",
    "      sys.stdout.write(\"{0:<8}\".format(\"{0:.3f}\".format(psi)))  \n",
    "      print(\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "  # If we just want to run the trained net\n",
    "  if len(sys.argv) > 1:\n",
    "    if sys.argv[1] == \"-r\":\n",
    "      datasets = init_data_sets(FLAGS)\n",
    "      run_saved(datasets)\n",
    "      sys.exit()\n",
    "\n",
    "  datasets = init_data_sets(FLAGS)\n",
    "  graph = create_graph()\n",
    "  run_session(graph, datasets)\n",
    "  run_saved(datasets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
