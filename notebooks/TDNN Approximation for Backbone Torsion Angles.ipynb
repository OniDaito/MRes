{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDNN Approximation\n",
    "\n",
    "This is my best attempt at approximating a TDNN for the purposes of working out the backbone angles for CDR-H3 loops. It performs better than random at least but overall, not too well.\n",
    "\n",
    "This is the result of several versions (well 2 previous) and a lot of fiddling to get things to a reasonable state. I can't say for sure yet, whether or not the 1D convolution is doing the TDNN bit of things well but my *guess* is that it is close enough for this iteration.\n",
    "\n",
    "## Data wrangling\n",
    "\n",
    "The data is initially pulled from the Dr Andrew Martin provided *abdab* dataset. This data is parsed as follows:\n",
    "\n",
    "* Take every model and look for the residues marked 95 to 105 inclusive on the heavy chain\n",
    "* Work out the torsion angles in radians. Save these in the *bio* way - i.e clockwise and anticlockwise -180 to +180\n",
    "* Convert this postgresql database into a set of numpy arrays\n",
    "* Change the phi and psi angles to be cos(phi), sin(phi), cos(psi), sin(phi) to smooth over discontinuities\n",
    "* Split the data randomly into 3 sets: 80% train, 10% test, 10% validation\n",
    "* Save this data as a pickle_file\n",
    "\n",
    "The acids are represented as a bitfield, 21 units long, e.g\n",
    "\n",
    "    0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
    "\n",
    "... would represent a Valine. This is a very sparse encoding and I'm sure we can totally improve on that. In Natural Language processing, things like word vectors, continuous bag of words and the like are used. We could investigate that.\n",
    "\n",
    "This online example uses the pickle file as I haven't uploaded the database to this server yet. I figure it's not essential.\n",
    "\n",
    "## Neural Net Design\n",
    "\n",
    "Tensorflow doesn't really do TDNNs but from what I can tell, a convolutional operation is the one we need. It means that the weights are shared as the kernel is convolved across the input. We use a **1 x window_size 1D kernel** that slides over each CDR. \n",
    "\n",
    "CDRs are provided in batches, though I've found that just providing 1 CDR at a time works best. Our input is **1 x max_cdr_length * 21 **, 21 being the number of amino acids. The **maximum CDR length is determined as 31** as this was the largest I found in my database.\n",
    "\n",
    "The problem of course is that neural networks don't do so well if the input size changes. In addition Tensorflow doesn't seem to have a custom dropout function; it's just random! So what I do is create a mask for the two fully connected layers that contains a 1 if that neuron is activated, and a 0 if it is to be ingnored. If a CDR is less than 31 residues in length, we pad the end of it with -3.0, -3.0, -3.0, -3.0 for the angles (-3.0 can never occur) and a bitmask of all zeroes for the input.\n",
    "\n",
    "I have two fully connected layers of neurons. There are 124 of them I believe with many, many weights coming in from the conv layer. The hiden layer could potentially be expanded to see if we can improve performance perhaps?\n",
    "\n",
    "The cost function takes the mask into account as well. We are attempting to minimise the squared difference between the expected angles and the produced angles. We use the mask to calculate which angles and inputs to include, add all the differences together and divide by the total.\n",
    "\n",
    "Our accuracy reading is determined using the validation set, which never gets trained against. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nn02.py - Dealing with variable length input\n",
    "author : Benjamin Blundell\n",
    "email : me@benjamin.computer\n",
    "\n",
    "Based on https://www.tensorflow.org/get_started/mnist/pros\n",
    "and https://danijar.com/variable-sequence-lengths-in-tensorflow/\n",
    "\n",
    "This version performs the best so far and is probably closest\n",
    "to the TDNN we want to check\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys, os, math, random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from common.util import *\n",
    "from common import gen_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Setting of flags for our network\n",
    "\n",
    "Here is where we import the FLAGS variable (set in common) that holds the various settings for our Neural net run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = NNGlobals()\n",
    "# A higher learning rate seems good as we have few examples in this data set.\n",
    "# Would that be correct do we think?\n",
    "FLAGS.learning_rate = 0.35\n",
    "FLAGS.window_size = 4\n",
    "FLAGS.pickle_filename = 'pdb_martin_02.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Functions for various parts\n",
    "\n",
    "Various functions and subroutines for checking such as:\n",
    "* weight variable setting\n",
    "* Bias variable setting\n",
    "* 1D convolution\n",
    "* Create a mask for our output layers\n",
    "* The custom cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name ):\n",
    "  ''' TODO - we should check the weights here for our TDNN \n",
    "  For now I use truncated normals with stdddev of 0.1. Hopefully\n",
    "  some of these go negative.'''\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1, name=name)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "  initial = tf.constant(1.0, shape=shape, name=name)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv1d(x, W):\n",
    "  ''' Our convolution is what we use to replicate a TDNN though\n",
    "  I suspect we need to do a lot more.'''\n",
    "  return tf.nn.conv1d(x, W, stride=1, padding='SAME')\n",
    "\n",
    "def create_mask(batch):\n",
    "  ''' create a mask for our fully connected layer, which\n",
    "  is a [1] shape that is max_cdr * 4 long.'''\n",
    "  mask = []\n",
    "  for model in batch:\n",
    "    mm = []\n",
    "    for cdr in model:\n",
    "      tt = 1\n",
    "      if not 1 in cdr:\n",
    "        tt = 0\n",
    "      for i in range(0,4):\n",
    "        mm.append(tt)\n",
    "    mask.append(mm)\n",
    "  return np.array(mask,dtype=np.float32)\n",
    "    \n",
    "def cost(goutput, gtest):\n",
    "  ''' Our error function which we will try to minimise'''\n",
    "  # We find the absolute difference between the output angles and the training angles\n",
    "  # Can't use cross entropy because thats all to do with probabilities and the like\n",
    "  # Basic error of sum squares diverges to NaN due to gradient so I go with reduce mean\n",
    "  # Values of -3.0 are the ones we ignore\n",
    "  # This could go wrong as adding 3.0 to -3.0 is not numerically stable\n",
    "  mask = tf.sign(tf.add(gtest,3.0))\n",
    "  basic_error = tf.square(gtest-goutput) * mask\n",
    "  \n",
    "  # reduce mean doesnt work here as we just want the numbers where mask is 1\n",
    "  # We work out the mean ourselves\n",
    "  basic_error = tf.reduce_sum(basic_error)\n",
    "  basic_error /= tf.reduce_sum(mask)\n",
    "  return basic_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph creation\n",
    "\n",
    "The actual graph that we shall run on our machine and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph() :\n",
    "  ''' My attempt at creating a TDNN with the conv1d operation. We have one conv layer, and two fully\n",
    "  connected layers (which are quite large). We take a batch x max_cdr x amino_acid layer and output\n",
    "  a max_cdr * 4 layer for angle components. We use tanh activation functions throughout.'''\n",
    "  # Borrowed parts from https://stackoverflow.com/questions/41583540/custom-dropout-in-tensorflow#41584818\n",
    "  graph = tf.Graph()\n",
    "\n",
    "  with tf.device('/gpu:0'):\n",
    "    with graph.as_default():\n",
    "      # Input data - we use a 2D array with each 'channel' being an amino acid bitfield\n",
    "      # In this case, we only use one example at a time as each is a different length\n",
    "      tf_train_dataset = tf.placeholder(tf.bool, \n",
    "          [None, FLAGS.max_cdr_length, FLAGS.num_acids],name=\"train_input\") \n",
    "      output_size = FLAGS.max_cdr_length * 4\n",
    "      dmask = tf.placeholder(tf.float32, [None, output_size], name=\"dmask\")\n",
    "      x = tf.cast(tf_train_dataset, dtype=tf.float32)\n",
    "      \n",
    "      # According to the Tensorflow tutorial, the last two vars are input channels\n",
    "      # and output channels (both 21)\n",
    "      W_conv0 = weight_variable([FLAGS.window_size, \n",
    "        FLAGS.num_acids, FLAGS.num_acids] , \"weight_conv_0\")\n",
    "      b_conv0 = bias_variable([FLAGS.num_acids], \"bias_conv_0\")\n",
    "      \n",
    "      # Using tanh as an activation fuction as it is bounded over -1 to 1\n",
    "      # Don't have to use it here but we get better accuracy\n",
    "      h_conv0 = tf.tanh(conv1d(x, W_conv0) + b_conv0)\n",
    "  \n",
    "      # The second layer is fully connected, neural net.\n",
    "      dim_size = FLAGS.num_acids * FLAGS.max_cdr_length\n",
    "      W_f = weight_variable([dim_size, output_size], \"weight_hidden\")\n",
    "      b_f = bias_variable([output_size], \"bias_hidden\")\n",
    "      \n",
    "\n",
    "      # Apparently, the convolutional layer needs to be reshaped\n",
    "      # This bit might be key as our depth, our 21 amino acid neurons are being connected here\n",
    "      h_conv0_flat = tf.reshape(h_conv0, [-1, dim_size])\n",
    "      h_f = tf.tanh( (tf.matmul(h_conv0_flat, W_f) + b_f)) * dmask\n",
    "      \n",
    "      # It looks like I can't take a size < max_cdr and use it, because we have \n",
    "      # fixed sized stuff so we need to dropout the weights we don't need per sample  \n",
    "      # Find the actual sequence length and only include up to that length\n",
    "      # We always use dropout even after training\n",
    "      # Annoyingly tensorflow's dropout doesnt work for us here so I need to \n",
    "      # add another variable to our h_f layer, deactivating these neurons matched\n",
    "      test = tf.placeholder(tf.float32, [None, output_size], name=\"train_test\")\n",
    "\n",
    "      # Output layer - we don't need this because the previous layer is fine but\n",
    "      # we do get some accuracy increases with another layer/\n",
    "      # the right number of variables for us but I'll add another one anyway so we have three.\n",
    "      W_o = weight_variable([output_size, output_size], \"weight_output\")\n",
    "      b_o = bias_variable([output_size],\"bias_output\")\n",
    "\n",
    "      # I use tanh to bound the results between -1 and 1\n",
    "      y_conv = tf.tanh( ( tf.matmul(h_f, W_o) + b_o) * dmask, name=\"output\")\n",
    "      variable_summaries(y_conv, \"y_conv\")\n",
    "\n",
    "  return graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Running\n",
    "\n",
    "Here is where we run the session and spit out the values we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_session(graph, datasets):\n",
    "  ''' Run the session once we have a graph, training methodology and a dataset '''\n",
    "  with tf.device('/cpu:0'):\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "      training_input, training_output, validate_input, validate_output, test_input, test_output = datasets\n",
    "      # Pull out the bits of the graph we need\n",
    "      ginput = graph.get_tensor_by_name(\"train_input:0\")\n",
    "      gtest = graph.get_tensor_by_name(\"train_test:0\")\n",
    "      goutput = graph.get_tensor_by_name(\"output:0\")\n",
    "      gmask = graph.get_tensor_by_name(\"dmask:0\")\n",
    "      stepnum = 0\n",
    "      # Working out the accuracy\n",
    "      basic_error = cost(goutput, gtest) \n",
    "      # Setup all the logging for tensorboard \n",
    "      variable_summaries(basic_error, \"Error\")\n",
    "      merged = tf.summary.merge_all() \n",
    "      train_writer = tf.summary.FileWriter('./summaries/train',graph)\n",
    "      # So far, I have found Gradient Descent still wins out at the moment\n",
    "      # https://stackoverflow.com/questions/36162180/gradient-descent-vs-adagrad-vs-momentum-in-tensorflow\n",
    "      train_step = tf.train.GradientDescentOptimizer(FLAGS.learning_rate).minimize(basic_error)\n",
    "      #train_step = tf.train.AdagradOptimizer(FLAGS.learning_rate).minimize(basic_error) \n",
    "      #train_step = tf.train.AdamOptimizer(1e-4).minimize(basic_error)\n",
    "      #train_step = tf.train.MomentumOptimizer(FLAGS.learning_rate, 0.1).minimize(basic_error)\n",
    "      tf.global_variables_initializer().run()\n",
    "      print('Initialized')\t\n",
    "\n",
    "      while stepnum < len(training_input):\n",
    "        item_is, item_os = next_item(training_input, training_output, FLAGS)\n",
    "        mask = create_mask(item_is)\n",
    "        summary, _ = sess.run([merged, train_step],\n",
    "            feed_dict={ginput: item_is, gtest: item_os, gmask: mask})\n",
    "        \n",
    "        # Find the accuracy at every step, but only print every 100\n",
    "        mask = create_mask(validate_input)\n",
    "        train_accuracy = basic_error.eval(\n",
    "            feed_dict={ginput: validate_input, gtest: validate_output,  gmask : mask}) \n",
    "        \n",
    "        if stepnum % 100 == 0:\n",
    "          print('step %d, training accuracy %g' % (stepnum, train_accuracy))\n",
    "        \n",
    "        #dm = gmask.eval(feed_dict={ginput: item_is, gtest: item_os, gmask: mask}) \n",
    "        #print(dm)\n",
    "        train_writer.add_summary(summary, stepnum)\n",
    "        stepnum += 1\n",
    "\n",
    "      # save our trained net\n",
    "      saver = tf.train.Saver()\n",
    "      saver.save(sess, 'saved/nn02')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Trained net\n",
    "\n",
    "Here we run the network on a randomly chosen example from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_saved(datasets):\n",
    "  ''' Load the saved version and then test it against the validation set '''\n",
    "  with tf.Session() as sess:\n",
    "    graph = sess.graph\n",
    "    saver = tf.train.import_meta_graph('saved/nn02.meta')\n",
    "    saver.restore(sess, 'saved/nn02')\n",
    "    training_input, training_output, validate_input, validate_output, test_input, test_output = datasets\n",
    "    goutput = graph.get_tensor_by_name(\"output:0\")\n",
    "    ginput = graph.get_tensor_by_name(\"train_input:0\")\n",
    "    gmask = graph.get_tensor_by_name(\"dmask:0\")\n",
    "    mask = create_mask(validate_input)\n",
    "    res = sess.run([goutput], feed_dict={ginput: validate_input, gmask: mask })\n",
    "\n",
    "    # Now lets output a random example and see how close it is, as well as working out the \n",
    "    # the difference in mean values. Don't adjust the weights though\n",
    "    r = random.randint(0, len(validate_input)-1)\n",
    "\n",
    "    print(\"Actual              Predicted\")\n",
    "    for i in range(0,len(validate_input[r])):\n",
    "      sys.stdout.write(bitmask_to_acid(FLAGS, validate_input[r][i]))\n",
    "      phi = math.degrees(math.atan2(validate_output[r][i*4], validate_output[r][i*4+1]))\n",
    "      psi = math.degrees(math.atan2(validate_output[r][i*4+2], validate_output[r][i*4+3]))\n",
    "      sys.stdout.write(\": \" + \"{0:<8}\".format(\"{0:.3f}\".format(phi)) + \" \")\n",
    "      sys.stdout.write(\"{0:<8}\".format(\"{0:.3f}\".format(psi)) + \" \")\n",
    "      phi = math.degrees(math.atan2(res[0][r][i*4], res[0][r][i*4+1]))\n",
    "      psi = math.degrees(math.atan2(res[0][r][i*4+2], res[0][r][i*4+3]))\n",
    "      sys.stdout.write(\" | \" + \"{0:<8}\".format(\"{0:.3f}\".format(phi)) + \" \")\n",
    "      sys.stdout.write(\"{0:<8}\".format(\"{0:.3f}\".format(psi)))  \n",
    "      print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the whole thing\n",
    "\n",
    "Fairly self explanatory, this last block. It takes roughly **1 minute** on this server's CPU to run through the training so do give it a bit of time. It's much faster on a GPU of course, but I don't have all the money in the world to put one in my 1U rack at Telehouse! :D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from pickle file\n",
      "(2298, 31, 21) <class 'numpy.ndarray'> bool\n",
      "(2298, 124) <class 'numpy.ndarray'> float32\n",
      "Initialized\n",
      "step 0, training accuracy 0.905324\n",
      "step 100, training accuracy 0.509628\n",
      "step 200, training accuracy 0.466601\n",
      "step 300, training accuracy 0.505744\n",
      "step 400, training accuracy 0.480032\n",
      "step 500, training accuracy 0.527179\n",
      "step 600, training accuracy 0.553449\n",
      "step 700, training accuracy 0.519494\n",
      "step 800, training accuracy 0.487892\n",
      "step 900, training accuracy 0.55577\n",
      "step 1000, training accuracy 0.593868\n",
      "step 1100, training accuracy 0.505347\n",
      "step 1200, training accuracy 0.482474\n",
      "step 1300, training accuracy 0.51733\n",
      "step 1400, training accuracy 0.49749\n",
      "step 1500, training accuracy 0.543896\n",
      "step 1600, training accuracy 0.466765\n",
      "step 1700, training accuracy 0.509391\n",
      "step 1800, training accuracy 0.48828\n",
      "step 1900, training accuracy 0.504779\n",
      "step 2000, training accuracy 0.525433\n",
      "step 2100, training accuracy 0.493252\n",
      "step 2200, training accuracy 0.502474\n",
      "INFO:tensorflow:Restoring parameters from saved/nn02\n",
      "Actual              Predicted\n",
      "ARG: -71.565  169.057   | 40.434   164.982 \n",
      "GLY: -95.550  -92.982   | -85.825  135.035 \n",
      "PHE: -58.268  167.635   | -79.689  -42.095 \n",
      "HIS: -71.815  -35.774   | -92.435  6.817   \n",
      "GLY: -106.098 40.262    | 165.926  -94.493 \n",
      "SER: -155.027 114.982   | -97.752  107.138 \n",
      "TYR: -68.589  5.219     | -95.587  49.283  \n",
      "SER: -66.003  140.194   | -110.704 176.270 \n",
      "PHE: -86.341  98.575    | -99.566  127.951 \n",
      "ALA: -79.064  -29.384   | -99.415  -37.561 \n",
      "TYR: -117.519 129.273   | -121.544 136.030 \n",
      "TRP: -129.219 150.560   | -125.788 148.276 \n",
      "GLY: -84.466  170.754   | -76.660  161.171 \n",
      "GLN: -71.271  180.000   | -73.153  178.351 \n",
      "***: -135.000 -135.000  | -180.000 -180.000\n",
      "***: -135.000 -135.000  | -0.000   -180.000\n",
      "***: -135.000 -135.000  | -0.000   180.000 \n",
      "***: -135.000 -135.000  | -0.000   180.000 \n",
      "***: -135.000 -135.000  | -0.000   180.000 \n",
      "***: -135.000 -135.000  | -0.000   -180.000\n",
      "***: -135.000 -135.000  | -0.000   0.000   \n",
      "***: -135.000 -135.000  | -0.000   180.000 \n",
      "***: -135.000 -135.000  | 0.000    180.000 \n",
      "***: -135.000 -135.000  | 0.000    0.000   \n",
      "***: -135.000 -135.000  | 0.000    180.000 \n",
      "***: -135.000 -135.000  | 0.000    0.000   \n",
      "***: -135.000 -135.000  | -0.000   0.000   \n",
      "***: -135.000 -135.000  | -0.000   0.000   \n",
      "***: -135.000 -135.000  | 0.000    0.000   \n",
      "***: -135.000 -135.000  | 0.000    0.000   \n",
      "***: -135.000 -135.000  | 0.000    0.000   \n"
     ]
    }
   ],
   "source": [
    "datasets = init_data_sets(FLAGS)\n",
    "graph = create_graph()\n",
    "run_session(graph, datasets)\n",
    "run_saved(datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
